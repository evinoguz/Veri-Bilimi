{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kütüphanelerin yüklenmesi\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PM10_hci(PM10):\n",
    "    PM10_index=0\n",
    "    if PM10>=0 and PM10<=50:\n",
    "        PM10_index=1 # İyi\n",
    "    elif PM10>=51 and PM10<=100:\n",
    "        PM10_index=2 # Orta\n",
    "    elif PM10>=101 and PM10<=260:\n",
    "        PM10_index=3 # Hassas\n",
    "    elif PM10>=261 and PM10<=400:\n",
    "        PM10_index=4 # Sağlıksız\n",
    "    elif PM10>=401 and PM10<=520:\n",
    "        PM10_index=5 # Kötü\n",
    "    elif PM10>=521:\n",
    "        PM10_index=6 # Tehlikeli\n",
    "    return PM10_index\n",
    "        \n",
    "def SO2_hci(SO2):\n",
    "    SO2_index=0\n",
    "    if SO2>=0 and SO2<=100:\n",
    "        SO2_index=1\n",
    "    elif SO2>=101 and SO2<=250:\n",
    "        SO2_index=2\n",
    "    elif SO2>=251 and SO2<=500:\n",
    "        SO2_index=3\n",
    "    elif SO2>=501 and SO2<=850:\n",
    "        SO2_index=4\n",
    "    elif SO2>=851 and SO2<=1100:\n",
    "        SO2_index=5\n",
    "    elif SO2>=1101:\n",
    "        SO2_index=6\n",
    "    return SO2_index\n",
    "\n",
    "def CO_hci(CO):\n",
    "    CO_index=0\n",
    "    if CO>=0 and CO<=5500:\n",
    "        CO_index=1\n",
    "    elif CO>=5501 and CO<=10000:\n",
    "        CO_index=2\n",
    "    elif CO>=10001 and CO<=16000:\n",
    "        CO_index=3\n",
    "    elif CO>=16001 and CO<=24000:\n",
    "        CO_index=4\n",
    "    elif CO>=24001 and CO<=32000:\n",
    "        CO_index=5\n",
    "    elif CO>=32001:\n",
    "        CO_index=6\n",
    "    return CO_index\n",
    "\n",
    "def NO2_hci(NO2):\n",
    "    NO2_index=0\n",
    "    if NO2>=0 and NO2<=100:\n",
    "        NO2_index=1\n",
    "    elif NO2>=101 and NO2<=200:\n",
    "        NO2_index=2\n",
    "    elif NO2>=201 and NO2<=500:\n",
    "        NO2_index=3\n",
    "    elif NO2>=501 and NO2<=1000:\n",
    "        NO2_index=4\n",
    "    elif NO2>=1001 and NO2<=2000:\n",
    "        NO2_index=5\n",
    "    elif NO2>=2001:\n",
    "        NO2_index=6\n",
    "    return NO2_index\n",
    "    \n",
    "def O3_hci(O3):\n",
    "    O3_index=0\n",
    "    if O3>=0 and O3<=120:\n",
    "        O3_index=1\n",
    "    elif O3>=121 and O3<=160:\n",
    "        O3_index=2\n",
    "    elif O3>=161 and O3<=180:\n",
    "        O3_index=3\n",
    "    elif O3>=181 and O3<=240:\n",
    "        O3_index=4\n",
    "    elif O3>=241 and O3<=700:\n",
    "        O3_index=5\n",
    "    elif O3>=701:\n",
    "        O3_index=6\n",
    "    return O3_index\n",
    "\n",
    "\n",
    "# verisetinin yüklenmesi\n",
    "df=pd.read_excel('konya.xlsx', header=None, names=[\"Tarih\", \"PM10(µg/m³)\", \"SO2(µg/m³)\", \"CO(µg/m³)\", \"O3(µg/m³)\"])\n",
    "df=df.drop([0, 1], axis=0)\n",
    "\n",
    "\n",
    "# Eksik Verilerin Tamamlanması\n",
    "data=df.fillna(df.mean())\n",
    "\n",
    "# Hava Kalite İndexinin Oluşturulması\n",
    "dataindex=pd.DataFrame(data, columns=[\"Index\"])\n",
    "\n",
    "for i in range(len(data)):\n",
    "    pm10=PM10_hci(data.iloc[i][\"PM10(µg/m³)\"])\n",
    "    so2=SO2_hci(data.iloc[i][\"SO2(µg/m³)\"])\n",
    "    co=NO2_hci(data.iloc[i][\"CO(µg/m³)\"])\n",
    "    o3=O3_hci(data.iloc[i][\"O3(µg/m³)\"])\n",
    "    dataindex.iloc[i][\"Index\"]=max(pm10,so2,co,o3)\n",
    "\n",
    "\"\"\"\n",
    "#Verinini Görselleştirilmesi\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(data[\"Tarih\"],data[\"PM10(µg/m³)\"],color=\"g\")\n",
    "plt.title(\"PM10 Grafiği\")\n",
    "plt.ylabel(\"PM10\")\n",
    "plt.xlabel(\"Tarih\")\n",
    "plt.legend([\"PM10\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(data[\"Tarih\"],data[\"SO2(µg/m³)\"],color=\"g\")\n",
    "plt.title(\"SO2 Grafiği\")\n",
    "plt.ylabel(\"SO2\")\n",
    "plt.xlabel(\"Tarih\")\n",
    "plt.legend([\"SO23\"], loc=\"upper left\")\n",
    "plt.show()\n",
    " \n",
    "plt.plot(data[\"Tarih\"],data[\"CO(µg/m³)\"],color=\"g\")\n",
    "plt.title(\"CO Grafiği\")\n",
    "plt.ylabel(\"CO\")\n",
    "plt.xlabel(\"Tarih\")\n",
    "plt.legend([\"CO\"], loc=\"upper left\")\n",
    "plt.show()\n",
    " \n",
    "plt.plot(data[\"Tarih\"],data[\"O3(µg/m³)\"],color=\"g\")\n",
    "plt.title(\"O3 Grafiği\")\n",
    "plt.ylabel(\"O3\")\n",
    "plt.xlabel(\"Tarih\")\n",
    "plt.legend([\"O3\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# Verisetine index sütununun eklenmesi\n",
    "df=pd.concat([data, dataindex.Index.astype(int)],axis =1)\n",
    "\n",
    "#Sınıf sayısı ve etiketlerinin belirlenmesi\n",
    "label_encoder=LabelEncoder().fit(df.Index)\n",
    "labels=label_encoder.transform(df.Index)\n",
    "classes=list(label_encoder.classes_) # [ 1,2,3,4,5,6]\n",
    "\n",
    "#Girdi ve çoktiların hazırlanması\n",
    "X=df.drop([\"Tarih\",\"Index\"],axis=1)\n",
    "y=labels\n",
    "nb_features=4\n",
    "nb_classes=len(classes)\n",
    "\n",
    "# Değerlerin standartlaştırılması\n",
    "X=df.drop([\"Tarih\",\"Index\"],axis=1)\n",
    "X=SS().fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, = train_test_split(X,y,test_size = 0.2)\n",
    "\n",
    "#çıktı değerlerinin kategorileştirilmesi\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Girdi verilerinin yeniden boyutlandırılması\n",
    "X_train=np.array(X_train).reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_test=np.array(X_test).reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelin oluşturulması\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.python.keras.layers import Flatten,LSTM,BatchNormalization\n",
    "model= Sequential()\n",
    "model.add(LSTM(512,input_shape=(nb_features,1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add((Flatten()))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(2048, activation=\"relu\"))\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dense(nb_classes, activation=\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "#modelin derlenmesi\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelin eğitilmesi\n",
    "score = model.fit(X_train,y_train, epochs = 100, validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8425bb2a7aef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ortalama Eğitim Kaybı:\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ortalama Eğitim Başarımı:\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ortalama Doğrulama Kaybı:\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ortalama Doğrulama Başarımı:\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "print((\"Ortalama Eğitim Kaybı:\" , np.mean(model.history.history[\"loss\"])))\n",
    "print((\"Ortalama Eğitim Başarımı:\" , np.mean(model.history.history[\"accuracy\"])))\n",
    "print((\"Ortalama Doğrulama Kaybı:\" , np.mean(model.history.history[\"val_loss\"])))\n",
    "print((\"Ortalama Doğrulama Başarımı:\" , np.mean(model.history.history[\"val_accuracy\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eğitim ve doğrulama değerlerinin grafik üzerinde gösterilmesi\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(model.history.history[\"accuracy\"],color=\"b\")\n",
    "plt.plot(model.history.history[\"val_accuracy\"],color=\"r\")\n",
    "plt.title(\"Model Başarımları\")\n",
    "plt.ylabel(\"Başarım\")\n",
    "plt.xlabel(\"Epok Sayısı\")\n",
    "plt.legend([\"Eğitim\",\"Test\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"],color=\"g\")\n",
    "plt.plot(model.history.history[\"val_loss\"],color=\"r\")\n",
    "plt.title(\"Model kayıplar\")\n",
    "plt.ylabel(\"Kayıp\")\n",
    "plt.xlabel(\"Epok Sayısı\")\n",
    "plt.legend([\"Eğitim\",\"Test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
